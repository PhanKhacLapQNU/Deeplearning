import pathlib
import platform

# 1. KHáº®C PHá»¤C Lá»–I POSIXPATH (Quan trá»ng nháº¥t khi cháº¡y trÃªn Windows)
if platform.system() == 'Windows':
    pathlib.PosixPath = pathlib.WindowsPath

import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import tempfile
import os

# --- Cáº¤U HÃŒNH ---
st.set_page_config(page_title="AI Nháº­n Diá»‡n", page_icon="â›‘ï¸")

st.title("â›‘ï¸ Há»‡ thá»‘ng PhÃ¡t hiá»‡n MÅ© báº£o hiá»ƒm")
st.write(f"Äang cháº¡y trÃªn thÆ° má»¥c: `{os.getcwd()}`") # In ra thÆ° má»¥c hiá»‡n táº¡i Ä‘á»ƒ kiá»ƒm tra

# --- CÃ€I Äáº¶T ---
confidence = st.sidebar.slider("Äá»™ tin cáº­y", 0.0, 1.0, 0.45, 0.05)
model_path = "best.pt" 

# --- KIá»‚M TRA FILE Tá»’N Táº I KHÃ”NG ---
if not os.path.exists(model_path):
    st.error(f"âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file '{model_path}' trong thÆ° má»¥c nÃ y!")
    st.warning("ğŸ‘‰ Báº¡n hÃ£y copy file best.pt vÃ o cÃ¹ng thÆ° má»¥c vá»›i file app.py")
    st.stop() # Dá»«ng chÆ°Æ¡ng trÃ¬nh ngay náº¿u khÃ´ng cÃ³ file

# --- LOAD MODEL ---
@st.cache_resource
def load_model():
    try:
        # Load custom model
        model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=True)
        return model
    except Exception as e:
        st.error("âŒ Lá»—i khi táº£i Model!")
        st.code(f"Chi tiáº¿t lá»—i: {e}") # Hiá»‡n lá»—i cá»¥ thá»ƒ Ä‘á»ƒ dá»… sá»­a
        return None

with st.spinner("Äang táº£i model..."):
    model = load_model()

if model is None:
    st.error("âš ï¸ KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng á»©ng dá»¥ng do lá»—i Model.")
    st.stop()

# --- GIAO DIá»†N CHÃNH ---
st.success("âœ… Model Ä‘Ã£ táº£i thÃ nh cÃ´ng!")
model.conf = confidence

# ... (Pháº§n xá»­ lÃ½ video/áº£nh) ...
tab1, tab2 = st.tabs(["ğŸ–¼ï¸ áº¢nh", "ğŸ¥ Video"])

with tab2:
    uploaded_video = st.file_uploader("Chá»n video...", type=['mp4', 'avi'])
    if uploaded_video is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        
        if st.button("â–¶ï¸ Cháº¡y Video"):
            cap = cv2.VideoCapture(tfile.name)
            stframe = st.empty()
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret: break
                
                # --- CHá»– NÃ€Y LÃ€ CHá»– Báº N Bá»Š Lá»–I TRÆ¯á»šC ÄÃ“ ---
                # VÃ¬ mÃ¬nh Ä‘Ã£ check 'if model is None' á»Ÿ trÃªn rá»“i nÃªn á»Ÿ Ä‘Ã¢y sáº½ an toÃ n
                results = model(frame) 
                
                result_frame = np.squeeze(results.render())
                stframe.image(result_frame, channels="BGR", use_container_width=True)
            cap.release()
